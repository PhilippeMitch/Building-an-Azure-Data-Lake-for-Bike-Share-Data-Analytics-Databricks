{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "994ea536-eadf-4ffe-b61e-d6e8cd48a74e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Transform the data\n",
    "In this notebook we transformed the data into the star schema for a Gold data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35db7c40-254c-4c2e-b60a-b1ea946db978",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# Create a new schema\n",
    "spark.sql('''\n",
    "          CREATE SCHEMA IF NOT EXISTS gold\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbb1f25c-e47a-4fc6-a5ac-5914fbf933cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Dimension Riders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80143331-1115-41c2-851a-2aa1d9a33622",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+-------------------+----------+------------------+----------------+---------+\n|rider_id|first_name|last_name|            address|  birthday|account_start_date|account_end_date|is_member|\n+--------+----------+---------+-------------------+----------+------------------+----------------+---------+\n|    1000|     Diana|    Clark|1200 Alyssa Squares|1989-02-13|        2019-04-23|            null|     true|\n|    1001|  Jennifer|    Smith|    397 Diana Ferry|1976-08-10|        2019-11-01|      2020-09-01|     true|\n+--------+----------+---------+-------------------+----------+------------------+----------------+---------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "riders_df = spark.read.table(\"staging.riders\")\n",
    "riders_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af140b1f-7ab0-4ac2-8fd9-7f2c705ec0fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the dimension table\n",
    "riders_df.dropDuplicates([\"rider_id\"]).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.dim_riders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e80c7550-5ed5-48ef-a63f-c563197d0124",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\n|rider_id|first_name|last_name|             address|  birthday|account_start_date|account_end_date|is_member|\n+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\n|    1005| Christine|Rodriguez|224 Washington Mi...|1974-08-27|        2020-03-24|            null|    false|\n|    1008|      John| Crawford|    7691 Evans Court|1987-02-21|        2021-03-28|      2021-07-01|     true|\n+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.dim_riders;\n",
    "          ''').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63567fbf-00ef-476e-8d31-0538f2dd2b6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Dimension Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d38d872a-5dcf-4c56-86fb-faba56c29642",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------------+------------------+\n|  station_id|                name|         latitude|         longitude|\n+------------+--------------------+-----------------+------------------+\n|         525|Glenwood Ave & To...|        42.012701|-87.66605799999999|\n|KA1503000012|  Clark St & Lake St|41.88579466666667|-87.63110066666668|\n+------------+--------------------+-----------------+------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "stations_df = spark.read.table(\"staging.stations\")\n",
    "stations_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0072cb61-2247-4137-9095-d85f739409d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the station dimension table\n",
    "stations_df.dropDuplicates([\"station_id\"]) \\\n",
    "    .withColumnRenamed(\"name\", \"station_name\") \\\n",
    "    .write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"gold.dim_stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1062121-42ac-4c53-afe2-aac6ec083337",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------------+-----------------+\n|station_id|        station_name|        latitude|        longitude|\n+----------+--------------------+----------------+-----------------+\n|     13001|Michigan Ave & Wa...|41.8839840647265|-87.6246839761734|\n|     13006|LaSalle St & Wash...|       41.882664|        -87.63253|\n+----------+--------------------+----------------+-----------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.dim_stations;\n",
    "          ''').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ec8383f-0b96-466b-a5b7-de3a5672755d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Dimension Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28454f7d-a653-485e-ab97-a7eb34f69dd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb80f74c-9093-4506-8cd3-7c1b1ef64d32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|         trip_id|rideable_type|           start_at|           ended_at|start_station_id|end_station_id|rider_id|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|             525|           660|   71934|\n|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|             525|         16806|   47854|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "trips_df = spark.read.table(\"staging.trips\")\n",
    "trips_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e53c1a7-4469-4e65-a604-ea9bb1992eb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a partition by date\n",
    "min_date = trips_df.selectExpr('MIN(start_at) AS started_at').first().asDict()['started_at']\n",
    "max_date = trips_df.selectExpr('DATEADD(year, 5, MAX(start_at)) AS started_at').first().asDict()['started_at']\n",
    "expression = f\"sequence(to_date('{min_date}'), to_date('{max_date}'), interval 1 day)\"\n",
    "dim_dates = spark.createDataFrame([(1,)], [\"date_id\"])\n",
    "dim_dates = dim_dates.withColumn(\"dateinit\", f.explode(f.expr(expression)))\n",
    "dim_dates = dim_dates.withColumn(\"date\", f.to_timestamp(dim_dates.dateinit, \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d94f588a-5d60-44a4-9f98-3ef29da1d730",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------------+\n|date_id|  dateinit|               date|\n+-------+----------+-------------------+\n|      1|2021-02-01|2021-02-01 00:00:00|\n|      1|2021-02-02|2021-02-02 00:00:00|\n|      1|2021-02-03|2021-02-03 00:00:00|\n|      1|2021-02-04|2021-02-04 00:00:00|\n+-------+----------+-------------------+\nonly showing top 4 rows\n\n"
     ]
    }
   ],
   "source": [
    "dim_dates.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be30010a-619d-4d73-9b04-bcd144a7f37c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the dim_dates dateframe\n",
    "dim_dates_df = dim_dates \\\n",
    "            .withColumn(\"date_id\", f.regexp_replace(to_date(dim_dates.date), \"-\", \"\").cast(IntegerType())) \\\n",
    "            .withColumn(\"day\", f.dayofweek(dim_dates.date)) \\\n",
    "            .withColumn(\"week\", f.weekofyear(dim_dates.date)) \\\n",
    "            .withColumn(\"month\", f.month(dim_dates.date)) \\\n",
    "            .withColumn(\"quarter\", f.quarter(dim_dates.date)) \\\n",
    "            .withColumn(\"year\", f.year(dim_dates.date)) \\\n",
    "            .withColumn(\"is_weekend\", f.dayofweek(dim_dates.date).isin([1,7]).cast(\"int\")) \\\n",
    "            .drop(f.col(\"dateinit\")) \\\n",
    "            .drop(f.col(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9dab93d-9fae-4eb5-8029-80403e48c42c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------+----+----------+\n| date_id|day|week|month|quarter|year|is_weekend|\n+--------+---+----+-----+-------+----+----------+\n|20230530|  3|  22|    5|      2|2023|         0|\n|20240118|  5|   3|    1|      1|2024|         0|\n|20240212|  2|   7|    2|      1|2024|         0|\n|20240908|  1|  36|    9|      3|2024|         1|\n|20250528|  4|  22|    5|      2|2025|         0|\n+--------+---+----+-----+-------+----+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Let's diplay 52 rows from the dataframe\n",
    "dim_dates_df.dropDuplicates([\"date_id\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "446f3348-690d-44a5-b196-9aa9162c9b12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the dimension table\n",
    "dim_dates_df.dropDuplicates([\"date_id\"]).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.dim_dates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "759a156c-2680-4ce3-98bc-63f6c43555fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------+----+----------+\n| date_id|day|week|month|quarter|year|is_weekend|\n+--------+---+----+-----+-------+----+----------+\n|20230530|  3|  22|    5|      2|2023|         0|\n|20240118|  5|   3|    1|      1|2024|         0|\n+--------+---+----+-----+-------+----+----------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.dim_dates;\n",
    "          ''').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d0d5824-a96a-4891-8820-92ad753e72d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Fact Payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ef104a-d50d-4b54-9037-570fc6023f52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------+\n|payment_id|      date|amount|rider_id|\n+----------+----------+------+--------+\n|         1|2019-05-01|   9.0|    1000|\n|         2|2019-06-01|   9.0|    1000|\n+----------+----------+------+--------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "payments_df = spark.read.table(\"staging.payments\")\n",
    "payments_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2879137-f854-41d4-965b-61cdc7723d12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the payments fact table\n",
    "payments_df.dropDuplicates([\"payment_id\"]) \\\n",
    "    .write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"gold.fact_payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71348878-f16c-42f3-9708-09b8ed7af80a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------+\n|payment_id|      date|amount|rider_id|\n+----------+----------+------+--------+\n|       148|2017-09-01|  6.86|    1007|\n|       463|2021-09-01| 22.35|    1018|\n+----------+----------+------+--------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.fact_payments;\n",
    "          ''').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "943ef21e-0faf-4cbb-a20b-5968d0142f7e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Fact Trips\n",
    "\n",
    "For Fact Trips table we used spark.sql with a SQL query, we could have used pyspark.sql.DataFrame.join but it 's more work and we would need to upload the other tables in different dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72840710-4542-42b4-bd9d-ee1cbd082cff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|         trip_id|rideable_type|           start_at|           ended_at|start_station_id|end_station_id|rider_id|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|             525|           660|   71934|\n|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|             525|         16806|   47854|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "trips_df = spark.read.table(\"staging.trips\")\n",
    "trips_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d01599c-a043-44c7-898e-8ca8630254ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[68]: 4584921"
     ]
    }
   ],
   "source": [
    "trips_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9a9785e-c96c-4f39-956c-dffac24b12cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the data into a dataframe\n",
    "fact_trips_df = spark.sql('''\n",
    "                SELECT\n",
    "                    t.trip_id,\n",
    "                    t.rideable_type,\n",
    "                    t.start_at,\n",
    "                    t.ended_at,\n",
    "                    DATEDIFF(MINUTE, t.start_at, t.ended_at) AS Duration,\n",
    "                    DATEDIFF(YEAR, r.birthday, t.ended_at) AS rider_age,\n",
    "                    t.start_station_id,\n",
    "                    t.end_station_id,\n",
    "                    t.rider_id,\n",
    "                    REPLACE(p.date,\"-\", \"\") AS date_id\n",
    "                FROM staging.trips t\n",
    "                JOIN staging.riders r ON (t.rider_id=r.rider_id)\n",
    "                JOIN staging.payments p ON (t.rider_id=p.rider_id)\n",
    "            ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "684bfec5-7d44-49d1-9ec1-f8406867be5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[70]: 117816784"
     ]
    }
   ],
   "source": [
    "fact_trips_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98056123-8e01-422f-8ed0-8701ce6d6300",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From 4584921 to 117816784 is a lot, that's mean we have some duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bd9f3ce-54b1-4ad0-9630-c67b052b509c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+--------+\n|         trip_id|rideable_type|           start_at|           ended_at|Duration|rider_age|start_station_id|end_station_id|rider_id| date_id|\n+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+--------+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20220201|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20220101|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20211201|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20211101|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20211001|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20210901|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20210801|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20210701|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20210601|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|20210501|\n+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+--------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Let's display the first 10 rows to verify\n",
    "fact_trips_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3218a467-fd37-4541-aeba-6016c6fe3783",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We have noticed that we have some dupricates rows but we will drop the duplicates data before we insert them into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57803e9c-85d5-41ee-af9e-0a0fa86d180a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the trips fact table\n",
    "fact_trips_df.dropDuplicates([\"trip_id\"]) \\\n",
    "    .write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"gold.fact_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e28fa3f9-f5bc-4461-952d-789e0608e218",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+--------+\n|         trip_id|rideable_type|           start_at|           ended_at|Duration|rider_age|start_station_id|end_station_id|rider_id| date_id|\n+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+--------+\n|00000CAE95438C9D| classic_bike|2021-07-20 15:40:46|2021-07-20 17:38:17|     117|       22|           13022|  TA1305000003|   71748|20220201|\n|00001DCF2BC423F4|  docked_bike|2021-06-13 12:00:49|2021-06-13 12:29:51|      29|       39|           13008|  TA1307000048|   21478|20220201|\n|00002E8260690FFF| classic_bike|2021-09-29 17:43:26|2021-09-29 17:49:06|       5|       33|           13193|  TA1309000058|   23449|20220201|\n|0000578C9F82736A| classic_bike|2021-10-06 22:31:26|2021-10-06 23:03:50|      32|       42|           13257|  KA1503000041|   46411|20220101|\n|000086A0DF14F72F|electric_bike|2021-07-17 16:20:15|2021-07-17 16:56:50|      36|       35|    TA1309000002|         13398|   21055|20220201|\n|0000A12D4CC3EC2C|electric_bike|2021-10-23 16:43:44|2021-10-23 17:00:13|      16|       23|         20246.0|  TA1306000007|   66382|20220201|\n|0000BF799B6D88AB| classic_bike|2021-09-24 09:33:46|2021-09-24 09:51:55|      18|       26|    TA1306000016|         13050|   57939|20220201|\n|0000D31E18D1023C| classic_bike|2021-04-18 14:21:00|2021-04-18 14:34:01|      13|       30|           13001|  TA1307000117|   67773|20220201|\n|0000E98EC550CA61| classic_bike|2021-12-10 11:35:05|2021-12-10 11:37:16|       2|       17|    KA1503000034|  TA1305000009|   28452|20220201|\n|000113AD1F802A92| classic_bike|2021-02-08 07:56:43|2021-02-08 08:33:02|      36|       22|           13063|  TA1305000030|   62396|20220201|\n+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+--------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data and check if we still have the duplicates data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.fact_trips;\n",
    "          ''').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca1c5858-0dde-4992-a3b7-71fee875f97b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[74]: 4463338"
     ]
    }
   ],
   "source": [
    "# Check how many record we have in the table\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.fact_trips;\n",
    "          ''').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f5f68b-3b38-4503-b1b9-0d245eb1e05f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------+---------+---------+--------+------+-------------+----------+\n|         trip_id|      date|first_name|last_name|is_member|Duration|amount|rideable_type|is_weekend|\n+----------------+----------+----------+---------+---------+--------+------+-------------+----------+\n|07E0D1DCA9268F3C|2021-05-01|      John| Crawford|     true|       3|   9.0| classic_bike|         0|\n|07E0D1DCA9268F3C|2021-06-01|      John| Crawford|     true|       3|   9.0| classic_bike|         0|\n|07E0D1DCA9268F3C|2021-07-01|      John| Crawford|     true|       3|   9.0| classic_bike|         0|\n|07E0D1DCA9268F3C|2021-04-01|      John| Crawford|     true|       3|   9.0| classic_bike|         0|\n|0C50695A71DD5697|2021-05-01|      John| Crawford|     true|       8|   9.0| classic_bike|         0|\n+----------------+----------+----------+---------+---------+--------+------+-------------+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT t.trip_id, p.date, r.first_name, r.last_name, r.is_member, t.Duration, p.amount, t.rideable_type, d.is_weekend FROM gold.fact_trips t\n",
    "          JOIN gold.dim_dates d\n",
    "          ON t.date_id=d.date_id\n",
    "          JOIN gold.dim_riders r\n",
    "          ON r.rider_id=t.rider_id\n",
    "          JOIN gold.fact_payments p\n",
    "          ON p.rider_id=r.rider_id\n",
    "          ''').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aac09b6-b024-40b5-ba4e-f84cf03f6e2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transform_data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

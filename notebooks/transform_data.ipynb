{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "994ea536-eadf-4ffe-b61e-d6e8cd48a74e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Transform the data\n",
    "In this notebook we transformed the data into the star schema for a Gold data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35db7c40-254c-4c2e-b60a-b1ea946db978",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# Create a new schema\n",
    "spark.sql('''\n",
    "          CREATE SCHEMA IF NOT EXISTS gold\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbb1f25c-e47a-4fc6-a5ac-5914fbf933cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Dimension Riders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80143331-1115-41c2-851a-2aa1d9a33622",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+-------------------+----------+------------------+----------------+---------+\n|rider_id|first_name|last_name|            address|  birthday|account_start_date|account_end_date|is_member|\n+--------+----------+---------+-------------------+----------+------------------+----------------+---------+\n|    1000|     Diana|    Clark|1200 Alyssa Squares|1989-02-13|        2019-04-23|            null|     true|\n|    1001|  Jennifer|    Smith|    397 Diana Ferry|1976-08-10|        2019-11-01|      2020-09-01|     true|\n+--------+----------+---------+-------------------+----------+------------------+----------------+---------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "riders_df = spark.read.table(\"staging.riders\")\n",
    "riders_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af140b1f-7ab0-4ac2-8fd9-7f2c705ec0fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the dimension table\n",
    "riders_df.dropDuplicates([\"rider_id\"]).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.dim_riders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e80c7550-5ed5-48ef-a63f-c563197d0124",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\n|rider_id|first_name|last_name|             address|  birthday|account_start_date|account_end_date|is_member|\n+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\n|    1005| Christine|Rodriguez|224 Washington Mi...|1974-08-27|        2020-03-24|            null|    false|\n|    1008|      John| Crawford|    7691 Evans Court|1987-02-21|        2021-03-28|      2021-07-01|     true|\n+--------+----------+---------+--------------------+----------+------------------+----------------+---------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.dim_riders;\n",
    "          ''').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63567fbf-00ef-476e-8d31-0538f2dd2b6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Dimension Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d38d872a-5dcf-4c56-86fb-faba56c29642",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------------+------------------+\n|  station_id|                name|         latitude|         longitude|\n+------------+--------------------+-----------------+------------------+\n|         525|Glenwood Ave & To...|        42.012701|-87.66605799999999|\n|KA1503000012|  Clark St & Lake St|41.88579466666667|-87.63110066666668|\n+------------+--------------------+-----------------+------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "stations_df = spark.read.table(\"staging.stations\")\n",
    "stations_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0072cb61-2247-4137-9095-d85f739409d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the station dimension table\n",
    "stations_df.dropDuplicates([\"station_id\"]) \\\n",
    "    .withColumnRenamed(\"name\", \"station_name\") \\\n",
    "    .write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"gold.dim_stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1062121-42ac-4c53-afe2-aac6ec083337",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------------+-----------------+\n|station_id|        station_name|        latitude|        longitude|\n+----------+--------------------+----------------+-----------------+\n|     13001|Michigan Ave & Wa...|41.8839840647265|-87.6246839761734|\n|     13006|LaSalle St & Wash...|       41.882664|        -87.63253|\n+----------+--------------------+----------------+-----------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.dim_stations;\n",
    "          ''').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ec8383f-0b96-466b-a5b7-de3a5672755d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Dimension Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28454f7d-a653-485e-ab97-a7eb34f69dd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb80f74c-9093-4506-8cd3-7c1b1ef64d32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------+\n|payment_id|      date|amount|rider_id|\n+----------+----------+------+--------+\n|         1|2019-05-01|   9.0|    1000|\n|         2|2019-06-01|   9.0|    1000|\n+----------+----------+------+--------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "payments_df = spark.read.table(\"staging.payments\")\n",
    "payments_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e53c1a7-4469-4e65-a604-ea9bb1992eb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a partition by date\n",
    "w = Window.partitionBy('date').orderBy('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be30010a-619d-4d73-9b04-bcd144a7f37c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_dates_df = (payments_df.withColumn('rank',f.row_number().over(w)))\n",
    "unique_dates_df = (unique_dates_df.filter(unique_dates_df['rank'] == 1).drop('rank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9dab93d-9fae-4eb5-8029-80403e48c42c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------+\n|payment_id|      date|amount|rider_id|\n+----------+----------+------+--------+\n|      1890|2013-08-01|   6.7|    1072|\n|      1363|2014-05-01| 22.86|    1052|\n+----------+----------+------+--------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Let's diplay 2 rows from the dataframe\n",
    "unique_dates_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3573aeb-443e-4744-9e3a-f23467d6151f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create the dim_dates dataframe\n",
    "dim_dates_df = unique_dates_df \\\n",
    "    .withColumn(\"date_id\", regexp_replace(unique_dates_df.date, \"-\", \"\").cast(IntegerType())) \\\n",
    "    .withColumn(\"day\", f.dayofweek(unique_dates_df.date)) \\\n",
    "    .withColumn(\"week\", f.weekofyear(unique_dates_df.date)) \\\n",
    "    .withColumn(\"month\", f.month(unique_dates_df.date)) \\\n",
    "    .withColumn(\"quarter\", f.quarter(unique_dates_df.date)) \\\n",
    "    .withColumn(\"year\", f.year(unique_dates_df.date)) \\\n",
    "    .withColumn(\"is_weekend\", f.dayofweek(unique_dates_df.date).isin([1,7]).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95d9285f-cf27-413b-b110-5512de35cca1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------+----+----------+\n| date_id|day|week|month|quarter|year|is_weekend|\n+--------+---+----+-----+-------+----+----------+\n|20130201|  6|   5|    2|      1|2013|         0|\n|20130301|  6|   9|    3|      1|2013|         0|\n+--------+---+----+-----+-------+----+----------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Let's see the result\n",
    "dim_dates_df_ = dim_dates_df[[\"date_id\", \"day\", \"week\", \"month\", \"quarter\", \"year\", \"is_weekend\"]]\n",
    "dim_dates_df_.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "446f3348-690d-44a5-b196-9aa9162c9b12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the dimension table\n",
    "dim_dates_df_.dropDuplicates([\"date_id\"]).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.dim_dates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "759a156c-2680-4ce3-98bc-63f6c43555fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+-----+-------+----+----------+\n| date_id|day|week|month|quarter|year|is_weekend|\n+--------+---+----+-----+-------+----+----------+\n|20180301|  5|   9|    3|      1|2018|         0|\n|20200801|  7|  31|    8|      3|2020|         1|\n+--------+---+----+-----+-------+----+----------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.dim_dates;\n",
    "          ''').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d0d5824-a96a-4891-8820-92ad753e72d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Fact Payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ef104a-d50d-4b54-9037-570fc6023f52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------+\n|payment_id|      date|amount|rider_id|\n+----------+----------+------+--------+\n|         1|2019-05-01|   9.0|    1000|\n|         2|2019-06-01|   9.0|    1000|\n+----------+----------+------+--------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "payments_df = spark.read.table(\"staging.payments\")\n",
    "payments_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2879137-f854-41d4-965b-61cdc7723d12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the payments fact table\n",
    "payments_df.dropDuplicates([\"payment_id\"]) \\\n",
    "    .write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"gold.fact_payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71348878-f16c-42f3-9708-09b8ed7af80a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------+\n|payment_id|      date|amount|rider_id|\n+----------+----------+------+--------+\n|       148|2017-09-01|  6.86|    1007|\n|       463|2021-09-01| 22.35|    1018|\n+----------+----------+------+--------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.fact_payments;\n",
    "          ''').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "943ef21e-0faf-4cbb-a20b-5968d0142f7e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Fact Trips\n",
    "\n",
    "For Fact Trips table we used spark.sql with a SQL query, we could have used pyspark.sql.DataFrame.join but it 's more work and we would need to upload the other tables in different dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72840710-4542-42b4-bd9d-ee1cbd082cff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|         trip_id|rideable_type|           start_at|           ended_at|start_station_id|end_station_id|rider_id|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|             525|           660|   71934|\n|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|             525|         16806|   47854|\n+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the table\n",
    "trips_df = spark.read.table(\"staging.trips\")\n",
    "trips_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d01599c-a043-44c7-898e-8ca8630254ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[32]: 4584921"
     ]
    }
   ],
   "source": [
    "trips_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9a9785e-c96c-4f39-956c-dffac24b12cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the data into a dataframe\n",
    "fact_trips_df = spark.sql('''\n",
    "                SELECT\n",
    "                    t.trip_id,\n",
    "                    t.rideable_type,\n",
    "                    t.start_at,\n",
    "                    t.ended_at,\n",
    "                    DATEDIFF(MINUTE, t.start_at, t.ended_at) AS Duration,\n",
    "                    DATEDIFF(YEAR, r.birthday, t.ended_at) AS rider_age,\n",
    "                    t.start_station_id,\n",
    "                    t.end_station_id,\n",
    "                    t.rider_id,\n",
    "                    p.date date_id\n",
    "                FROM staging.trips t\n",
    "                JOIN staging.riders r ON (t.rider_id=r.rider_id)\n",
    "                JOIN staging.payments p ON (t.rider_id=p.rider_id)\n",
    "            ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "684bfec5-7d44-49d1-9ec1-f8406867be5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[30]: 117816784"
     ]
    }
   ],
   "source": [
    "fact_trips_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98056123-8e01-422f-8ed0-8701ce6d6300",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From 4584921 to 117816784 is a lot, that's mean we have some duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bd9f3ce-54b1-4ad0-9630-c67b052b509c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+----------+\n|         trip_id|rideable_type|           start_at|           ended_at|Duration|rider_age|start_station_id|end_station_id|rider_id|   date_id|\n+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+----------+\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2022-02-01|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2022-01-01|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2021-12-01|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2021-11-01|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2021-10-01|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2021-09-01|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2021-08-01|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2021-07-01|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2021-06-01|\n|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|       6|       37|             525|           660|   71934|2021-05-01|\n+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Let's display the first 10 rows to verify\n",
    "fact_trips_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3218a467-fd37-4541-aeba-6016c6fe3783",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We have noticed that we have some dupricates rows but we will drop the duplicates data before we insert them into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57803e9c-85d5-41ee-af9e-0a0fa86d180a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the trips fact table\n",
    "fact_trips_df.dropDuplicates([\"trip_id\"]) \\\n",
    "    .write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"gold.fact_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e28fa3f9-f5bc-4461-952d-789e0608e218",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+----------+\n|         trip_id|rideable_type|           start_at|           ended_at|Duration|rider_age|start_station_id|end_station_id|rider_id|   date_id|\n+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+----------+\n|00000CAE95438C9D| classic_bike|2021-07-20 15:40:46|2021-07-20 17:38:17|     117|       22|           13022|  TA1305000003|   71748|2022-02-01|\n|00001DCF2BC423F4|  docked_bike|2021-06-13 12:00:49|2021-06-13 12:29:51|      29|       39|           13008|  TA1307000048|   21478|2022-02-01|\n|00002E8260690FFF| classic_bike|2021-09-29 17:43:26|2021-09-29 17:49:06|       5|       33|           13193|  TA1309000058|   23449|2022-02-01|\n|0000578C9F82736A| classic_bike|2021-10-06 22:31:26|2021-10-06 23:03:50|      32|       42|           13257|  KA1503000041|   46411|2022-01-01|\n|000086A0DF14F72F|electric_bike|2021-07-17 16:20:15|2021-07-17 16:56:50|      36|       35|    TA1309000002|         13398|   21055|2022-02-01|\n|0000A12D4CC3EC2C|electric_bike|2021-10-23 16:43:44|2021-10-23 17:00:13|      16|       23|         20246.0|  TA1306000007|   66382|2022-02-01|\n|0000ADB008DC509C| classic_bike|2021-06-13 20:27:23|2021-06-13 20:53:06|      25|       19|    TA1308000001|  TA1308000001|   27439|2022-02-01|\n|0000BF799B6D88AB| classic_bike|2021-09-24 09:33:46|2021-09-24 09:51:55|      18|       26|    TA1306000016|         13050|   57939|2022-02-01|\n|0000D31E18D1023C| classic_bike|2021-04-18 14:21:00|2021-04-18 14:34:01|      13|       30|           13001|  TA1307000117|   67773|2022-02-01|\n|0000E98EC550CA61| classic_bike|2021-12-10 11:35:05|2021-12-10 11:37:16|       2|       17|    KA1503000034|  TA1305000009|   28452|2022-02-01|\n+----------------+-------------+-------------------+-------------------+--------+---------+----------------+--------------+--------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Verify the data and check if we still have the duplicates data\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.fact_trips;\n",
    "          ''').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca1c5858-0dde-4992-a3b7-71fee875f97b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[36]: 4463338"
     ]
    }
   ],
   "source": [
    "# Check how many record we have in the table\n",
    "spark.sql('''\n",
    "          SELECT * FROM gold.fact_trips;\n",
    "          ''').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93f5f68b-3b38-4503-b1b9-0d245eb1e05f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transform_data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
